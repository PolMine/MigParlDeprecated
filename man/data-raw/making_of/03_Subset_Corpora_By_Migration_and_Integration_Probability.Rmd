---
title: "03_Subset_Corpora_By_Migration_and_Integration_Probability"
author: "Christoph Leonhardt"
date: "03 November 2019"
output: html_document
---

# 3. Creating subcorpora based on the sum of migration and integration probability

Now we want to use this probability to create a subset of each regional corpus which fit the criteria of our first, topic modelling driven approach. The question is which estimated proportion of words of a speech does have to belong to a topic relevant to migration and integration in order to be part of the `MigParl` corpus [@Silge.2019]?

## Which probability?

In the logic of LDA topic models, each document - here: speech - does belong to each topic in varying order. 

```{r 03_example, echo = FALSE}
library(polmineR)
use("PopParl")
lda_model <- sprintf("%s/%s", system.file(package = "PopParl", "extdata", "supplementary_data", "topicmodels"), "lda_SL_2019-10-31_250_2019-10-31.rds") %>% 
  readRDS() 

sample_topic <- sort(round(topicmodels::posterior(lda_model)$topics[3,], 4), decreasing = TRUE)
sample_topic <- sort(sample_topic, decreasing = TRUE)[1:10]

model_terms <- topicmodels::terms(lda_model, 10)[,paste("Topic", names(sample_topic))]

model_desc <- lapply(1:10, 
       function(i) {
         model_char <- paste(model_terms[,i], collapse = ", ")
         names(model_char) <- colnames(model_terms)[i]
         return(model_char)
       }
    )


example_df <- data.frame("Topic_Number" = names(sample_topic), "Topic_Probability" = sample_topic, "Topic_Description" = unlist(model_desc), stringsAsFactors = FALSE)

DT::datatable(example_df, rownames = FALSE)
```




In consequence, even speeches which have very little relevance to migration and integration related issues could have a probability greater that zero to be part of the topic. One essential question is how we create an optimal trade-off between false positives (speeches which do have a numeric probability greater than the threshold we set but are not relevant) and false negatives (the other way around). In terms of machine learning, this can also be described as the trade-off between precision (to which extent does every document in a thematic subcorpus actually belong there) and recall (how many documents of the base population which do belong to the subcorpus are actually part of it). When choosing the topics we are using an approach which values reproducibility and inclusiveness over accuracy. Hence, the dictionary approach uses a deliberatively broad word list with a great deal of ambiguity. A lot of words will be used in other contexts as well but we are more concerned to miss out on a topic than to include too many topics (in other words: when in doubt, we prefer recall over precision). Choosing a proper threshold is a way to balance both demands.


## Trials

Since it is hard to tell a priori which would be a fitting threshold, we test it with the smallest parliament we have: The Saarland corpus. 

### Mean, max and min probabilities


```{r 03_test_with_sl_1, echo = FALSE}

all_speeches <- as.speeches("SL", s_attribute_name = "speaker")
list_of_all_probs <- lapply(all_speeches@objects, 
                            function(x) {
                              s_attributes(x, "migration_integration_probability")
                            }
)

mean_prob <- mean(as.numeric(unlist(list_of_all_probs)))
max_prob <- max(as.numeric(unlist(list_of_all_probs)))
min_prob <- min(as.numeric(unlist(list_of_all_probs)))
median_prob <- median(as.numeric(unlist(list_of_all_probs)))
```

Over all the mean probability of a speech to belong to migration and integration relevant topics is `r mean(as.numeric(unlist(list_of_all_probs)))` with a maximum value of `r max(as.numeric(unlist(list_of_all_probs)))` and a minimum value of `r min(as.numeric(unlist(list_of_all_probs)))`. Given the very small mean value, it might be unreasonable to assume a very high threshold which would capture only a very small subset of speeches.


### Proportions

In the following, we used several threshold values and calculated the proportion of the resulting subset to see if that is the case.

```{r 03_test_with_sl_2, echo = FALSE}
entire_corpus_size <- size("SL")

probs <- c(0.02, 0.05, 0.1, 0.2, 0.3, 0.4)
df <- data.frame()
for (prob in probs) {
  mig_int_speeches_02_size <- subset("SL", migration_integration_probability > prob) %>%
  size()
  size_percentage <- (mig_int_speeches_02_size/entire_corpus_size)*100
  cat(sprintf("A threshold of %s returns %s per cent of the corpus \n", prob, round(size_percentage, 2)))
  x <- data.frame(percentage = round(size_percentage, 2), threshold = prob)
  df <- rbind(df, x)
}

# this is an ugly way to do it but lapply has problems here with finding the correct s attribute
```

The proportion of the subset size and the corpus size varies from `r paste0(df[which(df$percentage == max(df$percentage)), "percentage"], "%")` with a threshold of `r df[which(df$percentage == max(df$percentage)), "threshold"]` to `r paste0(df[which(df$percentage == min(df$percentage)), "percentage"], "%")` with a threshold of `r df[which(df$percentage == min(df$percentage)), "threshold"]`. Intuitively certainly more than one percent of the speeches held in a German parliament would be related to some form of migration and integration relevant topic. Hence, we qualitatively check whether the smaller thresholds (0.02, 0.05, 0.1 and 0.2) yield reasonable results in terms of relevant speeches returned.


```{r 03_test_with_sl_3, echo = FALSE}

lda_model <- sprintf("%s/%s", system.file(package = "PopParl", "extdata", "supplementary_data", "topicmodels"), "lda_SL_2019-10-31_250_2019-10-31.rds") %>% readRDS()
topics_per_state <- readRDS("./rds/all_state_topics.rds")
topic_numbers <- as.integer(topics_per_state[grepl("SL", names(topics_per_state))])

topic_words <- terms(lda_model, 100)[,topic_numbers]

mig_int_speeches_02 <- subset("SL", migration_integration_probability > 0.02) %>%
  as.speeches(s_attribute_name = "speaker")

mig_int_speeches_05 <- subset("SL", migration_integration_probability > 0.05) %>%
  as.speeches(s_attribute_name = "speaker")

mig_int_speeches_1 <- subset("SL", migration_integration_probability > 0.1) %>%
  as.speeches(s_attribute_name = "speaker")

mig_int_speeches_2 <- subset("SL", migration_integration_probability > 0.2) %>%
  as.speeches(s_attribute_name = "speaker")
```

### Checking qualitatively

We can read a couple of speeches which were returned by different thresholds. To make the judgement easier, we highlight the words which were matched against the dictionary to determine relevance. Here, we print one sample speech:

```{r 03_test_with_sl_4, echo = FALSE}
read(mig_int_speeches_2[[1]], highlight = list(yellow = as.character(topic_words)))
```


### Conclusion - Probability Threshold of 0.05

The smallest threshold of 0.02 which is twice the mean of the probabilities, is certainly not restrictive enough. Checking manually, we do have a lot of false positives. As for the highest threshold of 0.2 (which is the case for the speech shown above), we have only relevant speeches but at the same time we cover only a small portion of the initial corpus. Hence, we do expect a lot of false negatives as well. A threshold of 0.05 seems to be the best trade-off from this point of view. There is no guarantee that this is the case for all parliaments we subset but it is our best guess going forward.

## Create subcorpora for all 16 regional parliaments

We subset each regional corpus by the migration and integration probability. In addition, to account for the varying coverage of the regional state corpora, we limit the time range to 2000 to 2018. This safeguards comparability within the corpus as almost all of the regional states are part of the entire time span (apart from Saarland which only starts in 2005 and Rhineland-Palatinate which starts in 2001). In addition, this aligns `MigParl` with other resources of the MigTex project. To later combine the speeches found with this first topic modelling driven approach, we extract the speech names only at this point. The actual decoding will be performed later.


```{r 03_prep_subsetting, echo = FALSE}
library(polmineR)
corpora <- c("BB", "BE", "BW", "BY", "HB", "HE", "HH", "MV", "NI", "NW", "RP", "SH", "SL", "SN", "ST", "TH")
package_to_use <- "PopParl"
use(package_to_use)
```

```{r 03_create_subcorpora, echo = FALSE}
list_of_subcorpora <- lapply(corpora, 
                             function(corpus) {
                               part <- polmineR::subset(corpus, migration_integration_probability > 0.05 & year >= 2000 & year <= 2018)
                             }
)

speech_list <- lapply(list_of_subcorpora, 
       function(part) {
         speeches <- s_attributes(part, "speech")
       }
)

names(speech_list) <- corpora

saveRDS(speech_list, "./rds/speech_lists_topic_modelling.rds")
```

